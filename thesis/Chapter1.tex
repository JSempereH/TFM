\chapter{Introduction}
\label{ch:Introduction}

\section{Privacy in the Big Data era}

In today's interconnected world, data is often referred to as the new oil, a resource of immense value. The surge of big data has revolutionized industries, transforming the way businesses operate and decisions are made. From personalized marketing to predictive analytics, big data enables a level of insight previously unimaginable. However, alongside these benefits, the proliferation of data has brought significant concerns regarding privacy. As data collection and processing become more pervasive, the importance and necessity of privacy in the big data era cannot be overstated.\\
Big data refers to extremely large datasets that can be analyzed computationally to reveal patterns, trends, and associations, particularly relating to human behavior and interactions. The volume, velocity, and variety of data generated today are unprecedented, driven by the ubiquity of internet-connected devices, social media, and advanced sensors. Companies and governments harness this data to optimize operations, enhance customer experiences, and improve public services. While the benefits of big data are clear, they come at a cost. The more data is collected, the greater the risk of privacy breaches. This creates a paradox: individuals want personalized services that require data sharing, yet they also desire privacy. This tension is at the heart of the privacy debate in the big data era. Users often unknowingly trade their privacy for convenience, sometimes with far-reaching consequences.
The loss of privacy due to big data can lead to several risks:

\begin{itemize}
    \item \textbf{Identity theft and fraud:} Personal data, if accessed by malicious actors, can be used to steal identities and commit fraud. With detailed personal information, criminals can impersonate individuals to access financial accounts, apply for loans, or engage in other fraudulent activities.
    \item \textbf{Surveillance and Profiling:} Extensive data collection enables the creation of detailed profiles of individuals. Governments and corporations can use these profiles for surveillance, often infringing on civil liberties. The ability to monitor and predict individuals' actions poses a significant threat to personal freedom and autonomy.
    \item \textbf{Discrimination and bias:} Big data algorithms, often used in decision-making processes, can perpetuate and amplify biases present in the data. This can lead to discriminatory practices in areas like hiring, lending, and law enforcement. Ensuring data fairness and preventing algorithmic bias is crucial to maintain equity.
    \item \textbf{Loss of trust:} When organizations fail to protect personal data, they risk losing the trust of their customers. High-profile data breaches have shown that trust, once lost, is hard to regain. Consumers are increasingly aware of privacy issues, and companies must prioritize data protection to maintain their reputation.
\end{itemize}

\subsection{What is Privacy-Enhancing Machine Learning}

Privacy-Enhancing Machine Learning (PEML) encompasses a range of techniques designed to train machine learning models while protecting the privacy of the data involved. PEML leverages cryptographic methods and algorithmic strategies to ensure that sensitive information is not exposed during the training or inference processes. In order to achieve this, several techniques are being developed:\\

\begin{itemize}
    \item \textbf{Homomorphic encryption:} Allows computations to be performed on encrypted data without needing to decrypt it first. This ensures that data remains secure throughout the computation process.
    \item \textbf{Secure Multi-Party Computation:} Enables multiple parties to collaboratively compute a function (i.e. an algorithm) over their inputs while keeping those inputs private.
    \item \textbf{Differential privacy:} Adds noise to the data or the outputs of queries to prevent the identification of individuals within a dataset. It provides mathematical guarantees that individual data points cannot be distinguished.
    \item \textbf{Federated Learning:} A decentralized approach to machine learning where the model training occurs across multiple devices or servers (nodes) that hold local data samples. Instead of sharing raw data, only model updates (like gradients) are exchanged and aggregated to improve the global model.
    \item \textbf{Anonymization and Pseudonymization:} These techniques remove or alter personally identifiable information, reducing the risk of re-identification. Anonymization makes data non-attributable to an individual, while pseudonymization replaces private identifiers with fake ones.
\end{itemize}



\subsection{EU and Spanish regulation}
Both individuals and organizations have roles to play in protecting privacy. Individuals should be educated about privacy risks and empowered to make informed decisions about their data. This includes understanding the privacy policies of services they use and taking advantage of tools to manage their data preferences.\\
Organizations, on the other hand, must adopt a proactive approach to privacy. This involves not only complying with legal requirements but also going beyond to implement best practices in data protection. Regular privacy impact assessments, robust data security measures, and transparent communication with users are essential.

In recent years, data governance has emerged as a critical area of focus both within the European Union (EU) and at the local level in Spain. These efforts are driven by regulatory initiatives and strategic frameworks aimed at maximizing the societal and economic benefits of data while ensuring transparency, accessibility, and a responsible management. The European Union has been proactive in shaping data governance policies to harness the potential of data-driven economies. A cornerstone of this effort is the EU Data Act, a legislative proposal introduced by the European Commission in 2023 [añadir cita].\\
The EU Data Act seeks to establish unified rules governing the access, sharing, and reuse of data generated across all economic sectors within the EU.
Central to the objectives of the EU Data Act is the promotion of fairness in the digital environment. It aims to create a level playing field for businesses by ensuring equitable access to data. This access is intended to stimulate a competitive data market, foster innovation, and facilitate the development of new data-driven services and products. By clarifying data usage rights for consumers and businesses, the Act aims to enhance trust in digital services and support Europe's broader digital transformation goals.
The Act addresses the underutilization of industrial data, which has been a significant challenge despite the exponential growth in data volume globally. By promoting data sharing and ensuring compliance with European data protection regulations such as the General Data Protection Regulation (GDPR), the EU seeks to unlock the economic potential of unused data. It is estimated that the EU Data Act could contribute substantially to GDP growth, positioning Europe as a leader in the global data economy by 2030. Complementing the EU Data Act is the EU Data Strategy, which provides a comprehensive framework for leveraging data to drive economic growth and societal progress. The strategy is built on Digital Principles that emphasize empowering consumers and businesses with greater control over their data. By encouraging sustainable practices and supporting the development of a competitive data market, the EU Data Strategy aims to capitalize on the transformative potential of data across various sectors, including healthcare, agriculture, and transport.\\

At the local level in Spain, the Spanish Federation of Municipalities and Provinces (FEMP) has implemented a Model Ordinance on Data Governance to standardize and enhance data management practices across municipal administrations [añadir cita]. This initiative is part of broader efforts to improve transparency, efficiency, and decision-making processes through effective data governance. The FEMP Model Ordinance on Data Governance highlights the strategic importance of data as a valuable asset for local administrations. It addresses various aspects of data governance, including data acquisition, management, exploitation, and openness. By promoting equal access to data and encouraging its reuse, the ordinance aims to maximize the benefits of data for local communities and support evidence-based policymaking.
Aligned with the principles of the GDPR, the ordinance places a strong emphasis on data privacy and the anonymization of data to protect individual rights. It also recognizes the critical role of data in supporting emerging technologies such as artificial intelligence (AI). The ordinance advocates for the use of quality data to train AI models effectively, thereby enhancing the accuracy and reliability of AI-driven solutions implemented by local governments.\\

The initiatives discussed underscore the intersection of EU-wide data governance policies and local implementation strategies within member states like Spain. While the EU Data Act aims to harmonize data regulations across member states to facilitate cross-border data flows and innovation, local initiatives such as the FEMP Model Ordinance on Data Governance provide tailored approaches to address specific regional needs and challenges. The synergy between EU and local initiatives is crucial for promoting a cohesive approach to data governance that balances regulatory compliance with local autonomy and innovation. By aligning with EU standards and guidelines, local administrations can leverage best practices in data management and governance to enhance service delivery, improve citizen engagement, and optimize resource allocation.


\subsection{Use cases}

Although not all use cases of this technology can be listed, such as collaboration between state and international administrations, research laboratory collaboration, collaboration for detecting tax fraud, etc., we will mention some of the use cases where research has been most focused and practical implementations currently exist.

\begin{itemize}
    \item \textbf{Healthcare sector:} One of the most promising applications of PEML is within the healthcare sector. Medical institutions collect vast amounts of sensitive patient data to improve diagnostics and treatment outcomes. However, the utilization of this data must be handled with extreme care to protect patient privacy. PEML techniques such as federated learning enable healthcare providers to collaborate on improving machine learning models without sharing raw patient data. This decentralized approach ensures that sensitive information remains secure within individual institutions while still benefiting from collective insights.
    \item \textbf{Financial services:} In the realm of financial services, institutions face rigorous regulatory requirements to safeguard customer information. At the same time, they seek to leverage customer data to personalize services and detect fraudulent activities. PEML techniques like differential privacy allow financial institutions to aggregate customer data while obscuring individual identities. This ensures compliance with privacy regulations without compromising the utility of data-driven insights.
    \item \textbf{Smart cities and IoT:} As cities become more interconnected through the Internet of Things (IoT), vast amounts of data are generated from sensors and devices. Smart city initiatives rely on this data to optimize urban planning, transportation systems, and public services. PEML plays a critical role in preserving citizen privacy by anonymizing data streams. By implementing techniques such as homomorphic encryption, cities can analyze encrypted data without decrypting it, thereby protecting the privacy of individuals while extracting valuable insights for urban development.
    \item \textbf{E-commerce:} E-commerce platforms thrive on understanding consumer behavior to offer personalized recommendations and targeted advertisements. However, this reliance on user data raises concerns about privacy infringement. PEML solutions like multi-party computation enable e-commerce companies to collaborate with data providers and advertisers without directly exposing individual user preferences. By jointly analyzing encrypted data, these platforms can tailor offerings to user interests while preserving user anonymity.
\end{itemize}


\section{Multilayer Perceptrons}
\label{sec:Multilayer_Perceptron}
A Multilayer Perceptron (MLP), also known as feedforward neural network, is a mathematical model mainly used in supervised learning. Essentially, an MLP is a directed acyclic graph which represents the composition of functions. Each function or \textbf{layer} is a collection of neurons. A neuron is defined as:

\begin{equation}
    \label{eqn:neuron}
    y = f(\mathbf{x}; \theta) = \omega^T \mathbf{x} + b, \qquad \theta = (\omega, b)
\end{equation}

The term \textit{perceptron} refers to a linear classifier consisting of one layer \cite{rosenblatt1958}, $f(\mathbf{x}; \theta) = \mathbb{I}(\omega^T \mathbf{x} + b > 0)$.
Here, $\mathbb{I}(a>0)$ is the Heaviside function, which is non-differentiable. In MLP, the activation function from the original perceptron $\mathbb{I}$ is usually replaced by another differentiable function $\psi \colon \mathbb{R} \to \mathbb{R}$. The internal layers of MLP are usually named \textbf{hidden layers}, the last one is called \textbf{output layer}. The dimensionality of the hidden layers determines the \textbf{width} of the neural network \cite{goodfellow2016}. Each layer $l$ consists of many units $\mathbf{z}_l$ which are computed as a linear transformation of the units from the previous layer $l-1$ passed element-wise through the activation function \cite{murphy2022}:
\begin{equation*}
    \mathbf{z}_l = \psi_l (\mathbf{W}_l \mathbf{z}_{l-1} + \mathbf{b}_l)
\end{equation*}

We can choose different activation functions that will define our model and impact in the performance of the training. If we use a linear activation function $\psi_l (x) = K_l x$ then our neural network becomes just a linear model \cite{murphy2022}, that's why usually non-linear activation functions are used, since we would like to capture non-linear relationships between the input data and the output. Also, the Universal Approximation Theorem states that a neural network with a single hidden layer and non-linear activation functions can approximate any continuous function on a compact subset of $\mathbb{R}^n$ to any desired degree of accuracy.
Since the goal of an MLP is to approximate some function $f^*$ (for example, for a classifier $y = f^*(\mathbf{x})$), non-linear activation functions are necessary to achieve this level of approximation.
However, they can be used when we know the problem is linearly separable (think of two separate clusters of points in $\mathbb{R}^2$ in a classifier model) or in the output layer, for example when the MLP acts as a regression model.\\
If we change the Heaviside function by the sigmoid (logistic) function $\sigma(x) = \frac{1}{1+e^{-x}}$ we get a smooth approximation of $\mathbb{I}$. Another choice of activation function could be $tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$ which has a similar shape but its image is $(-1,1)$. Both are valid activation function and have been used. However, since we need to compute gradients in the optimization process in order to update the weights, a $\mathbf{0}$ gradient would be a problem, since it will make hard to train a model using gradient descent (vanishing gradient problem).
Both functions have an almost horizontal slope (gradient near 0) for large positive and negative inputs. Also, $\lVert \frac{d}{dx} \sigma(x) \rVert = \lVert \sigma(x)(1-\sigma(x)) \rVert \leq \frac{1}{4} < 1$, therefore several multiplications will quickly approximate to zero. Although they are used in practice (for example, $\sigma(\cdot)$ is used in the output layer for binary regression problems), in order to train deep models we need non-saturating activation functions for the hidden layers.
One of the most used is \textit{rectified linear unit}: $ReLU(x) = \max (a,0) = a \mathbb{I}(a>0)$. The gradient of $ReLU'(z) \neq 0$ as long as $z$ is positive: this function don't require input normalization to prevent them from saturating.
As stated in \cite*{glorot2011}, the rectifier activation function allows a network to easily obtain sparse representations, the \textit{hard} saturation (gradients being exactly 0) help supervised training: experimental results suggest that networks with ReLU activation functions in the hidden layers have better convergence performance than using sigmoid \cite{krizhevsky2017}.
There has been a lot of activation functions proposed in the last years, [TERMINAR ESTO] .\\

The neural network tries to approximate the target function $\mathbf{y} = F(\mathbf{x})$, the \textit{true} relation between the variables. The network, $f(x;\theta)$, \textit{learns} by searching the parameters $\boldsymbol{\theta}$ that minimizes a loss function $J(\boldsymbol{\theta})$, which measures the distance between the output and the target or the proximity between probability densities of random variables \cite*{calin2020}. If we consider a $k$-class classification problem with $\mathcal{X} \subset \mathbb{R}^d$ the feature space and $\mathcal{Y} = \{1,\dots, k\}$ the label space, given the dataset $D = \{(\mathbf{x}_1, y_1),\cdots,(\mathbf{x}_n, y_n)\}$ and a MLP $f\colon \mathcal{X} \to \mathbb{R}^k$ with a softmax as the output layer.
For any loss function $J(\boldsymbol{\theta}) = J(f(\mathbf{x}, \boldsymbol{\theta}), y)$, assuming there is a joint distribution $P(\mathbf{x},y)$ over $\mathcal{X}$ and $\mathcal{Y}$, the \textbf{risk} of $f$ is defined as $R_J (f) = \mathbb{E}\Bigl[ J(f(\mathbf{x}; \boldsymbol{\theta}), y) \Bigr] = \int J(f(\mathbf{x}; \theta), y) dP(\mathbf{x}, y)$ and the \textbf{empirical risk} is defined as $\hat{R}_J (f) = \mathbb{E}_D \Bigl[ J(f(\mathbf{x}; \boldsymbol{\theta}), y) \Bigr]$ assuming that $\{(\mathbf{x}_i, y_i)\}_{i=1}^n$ are IID samples from $P(\mathbf{x}, y)$.
Since the nonlinearity of an MLP makes the loss function to become non-convex, it's trained using iterative, gradient-based optimizers. Most neural networks, and in particular the models that will be used in this work, are trained using maximum likelihood: the loss function is the negative log-likelihood \footnote{Empirical risk minimization is equivalent to Maximum Likelihood Estimation when the risk is defined as the negative of the likelihood. Note that ERM does not limit itself to that particular class of risk functions.} \cite{goodfellow2016}. That is, we will compute the \textit{cross-entropy}\footnote{This is valid for a loss consisting of a negative log-likelihood, not only for the negative log-likelihodd of a softmax distribution.} between the training data and the model distribution:

\begin{equation}
    J(\theta) = -\mathbb{E}_{\mathbf{x}, y \sim D} \log_{P(\mathbf{x}, y)} (y | \mathbf{x})
\end{equation}
In a $k$-class classification model with a cross-entropy loss function, the empirical risk to minimize is $\hat{R}_J (f) = -\frac{1}{n}\sum_{i=1}^n \sum_{j=1}^k \mathbf{y}_{ij} \log f_j (\mathbf{x}_i; \boldsymbol{\theta})$, where $\mathbf{y}_{ij}$ is the j-th element of the one-hot encoded label of $\mathbf{x}_i$ such that $\mathbf{1}^T \mathbf{y}_i = 1$, $\forall i$, and $f_j$ is the j-th element of the softmax output layer of $f$ \cite{zhang2018}.\\

\section{Optimizer}
\label{sec:optimizer}
Typically, the minimization of $J(\boldsymbol{\theta})$ is achieved using a gradient descent algorithm. Large training datasets are good for generalization, but since $\nabla_{\boldsymbol{\theta}} J (\boldsymbol{\theta}) \frac{1}{n}\sum_{i=1}^n \nabla_{\boldsymbol{\theta}} l(f(\mathbf{x}; \boldsymbol{\theta}), y)$ has a computational complexity of $\mathcal{O}(n)$ for each step \cite{goodfellow2016}, this approach is prohibitive for $n$ in a scale of millions. Optimization algorithms that use the whole dataset are called \textbf{batch}\footnote{The term \textit{batch} may also refer to a subset of the training set. The size of a minibatch is usually called \textit{batch size}.} gradient methods.
When only a single sample is used each step, the method is called \textbf{stochastic}. The \textbf{Minibatch Stochastic Gradient Descent} (MSGD) algorithm (and its variants) is preferred, since the gradient direction in SGD oscillates because of the additional noise added by random sampling \cite{sun2019}.
The MSGD algorithm makes and estimation of the gradient selecting randomly a \textit{minibatch} $b = \{(\mathbf{x}, y)^{(1)},\cdots, (\mathbf{x}, y)^{(m)}\}$, $m<n$ such as:

\begin{equation}
    \label{eqn:gradient_estimate}
    \mathbf{g} = \frac{1}{m} \nabla_{\boldsymbol{\theta}} \sum_{i=1}^m l(f(\mathbf{x}^{(i)}; \boldsymbol{\theta}), y^{(i)})
\end{equation}

Each step of the MSGD algorithm, the parameters $\boldsymbol{\theta}$ are updated given a learning rate $\eta > 0$: $\boldsymbol{\theta} = \boldsymbol{\theta} - \eta \mathbf{g}$. A constant learning rate during training may lead to a zone where the gradient estimate "jumps around" a local minimum, although if the network is complex enough to represent the underlying function, a constant learning rate usually works well in practice \cite{sun2019a}. In some implementations, the learning rate is updated during training, an example could be multiplying by a factor $0<\gamma<1$ each $T$ number of steps\footnote{This is actually what the \textit{StepLR} class does in the popular Python package torch.optim.}.
Here, we encounter some challenges \cite{ruder2017}:

\begin{itemize}
    \item A small $\eta$ leads to slow convergence of vanilla MSGD, while if it's too large the loss function will fluctuate around the minimum or diverge.\\
    \item A learning rate scheduler needs to be defined at the beginning and it's not adapted to dataset's characteristics.\\
    \item Since $J(\boldsymbol{\theta})$ is non-convex (recall that affine transformations followed by an activation function such as ReLU is non-covex). A key challenge is avoiding getting trapped in suboptimal local minima. Also, according to \cite{dauphin2014}, the difficulty comes from saddle points present in high-dimensional non-convex optimization that are hard for SGD to scape, since the gradient is close to zero in all dimensions.
\end{itemize}

There are several gradient-based variants that try to tackle these challenges. For example, a momentum term can be used to help accelerate MSGD and dampen oscillations \cite{qian1999}.
Momentum stores the gradient of the past step to adjust the new direction:

\begin{align}
    \label{eqn:SGD_momentum}
    \begin{split}
    \mathbf{v}_t &= \alpha \mathbf{v}_{t-1} + \eta \nabla_{\boldsymbol{\theta}} J(\boldsymbol{\theta}) \qquad \eta>0, \hspace*{.3 em} \alpha \in [0,1] \\
    \boldsymbol{\theta} &= \boldsymbol{\theta} - \mathbf{v}_t
    \end{split}
\end{align}

The momentum term increases the updates for dimensions whose gradients point in the same direction, allowing the algorithm to build momentum and move more efficiently towards the minimum. Conversely, it reduces updates for dimensions whose gradients change direction, dampening out oscillations and preventing the algorithm from getting stuck in local minima \cite{ruder2017}.\\

Another variant is \textbf{Nesterov accelerated gradient} \cite{y1983}, which is an extension of Gradient Descent with momentum where the computation of the gradient is performed using projected parameters and not the actual values:

\begin{align}
    \label{eqn:Nesterov_accelerated_gradient}
    \begin{split}
        \mathbf{v}_t &= \alpha \mathbf{v}_{t-1} + \eta \nabla_{\boldsymbol{\theta}} J(\boldsymbol{\theta} - \alpha \mathbf{v}_{t-1}) \\
        \boldsymbol{\theta} &= \boldsymbol{\theta} - \mathbf{v}_t
    \end{split}
\end{align}

Here, similar to GD with momentum, $\mathbf{v}_t$ is the direction and speed at which the parameters should be tweaked and $\alpha$ determines how quickly the previous gradients will decay. Nesterov Accelerated Gradient tries to tackle the exploding gradient case: where the velocity added to the parameters gives an unwanted high loss. In this case, if the velocity update lead to a bad loss, the gradients will redirect the update back to $\boldsymbol{\theta}$.

[PONER IMAGEN QUE COMPARE MOMENTUM CON NAG]

Still, with the previous algorithms the hyperparameters $\eta$ and $\alpha$ need to be fixed or changed during training a heuristic way. With the \textbf{Adaptative Gradient Algorithm} (\textbf{Adagrad}), the learning rate change depending on the parameters: it performs larger updates for infrequent parameters and smaller updates for frequent parameters. That's it, each parameter is updated with a different learning rate each step.
We set $g_{t,i}$ the gradient estimate w.r.t the parameter $\theta_i$ at step $t$. The Adagrad update rule is:

\begin{equation}
    \label{eqn:Adagrad}
    \theta_{t+1, i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,i} + \epsilon}} g_{t,i}
\end{equation}

Where $G_{t,i}$ is the sum of squares of the gradients w.r.t $\theta_i$ up to step $t$, and $\epsilon > 0$ is the decimal smallest number in the machine, in order to avoid division by zero. With Adagrad, the selection of $\eta$ is irrelevant since the term will be scaled by the root. Most implementations just fix it at $0.01$. The problem with this algorithm is that the accumulated sums will increase during training and eventually the learning rate will be close to zero, therefore the parameters are not updated at a certain point.
In order to fix this, \textbf{Adadelta} restricts the number of accumulated gradients to some fixed size $w$ \cite{zeiler2012}. Since storing $w$ previous squared gradients is inefficient, it was proposed to compute an exponentially decaying average of the squared gradients, given a decay constant $\rho \in (0,1)$, similar to that used in Momentum. So, let $\mathbf{g}_t$ be the estimate of $\nabla_{\boldsymbol{\theta}} J(\boldsymbol{\theta}_t)$, $\mathbf{v}$ and $\mathbf{u}$ the square average and the accumulated variable resp., both initialized at $\mathbf{0}$ and $\lambda>0$ the weight decay, the Adadelta algorithm is:

\begin{align}
    \label{eqn:Adadelta}
    \begin{split}
        \mathbf{g}_t &\gets \mathbf{g_t} + \lambda \boldsymbol{\theta}_{t-1}\\
        \mathbf{v}_t &\gets \mathbf{v}_{t-1} \rho + \mathbf{g}_t^2 (1-\rho)\\
        \Delta \mathbf{x}_t &\gets \frac{\sqrt{\mathbf{u}_{t-1} + \epsilon}}{\sqrt{\mathbf{v}_t + \epsilon}} \mathbf{g}_t\\
        \mathbf{u}_t &\gets \mathbf{u}_{t-1} \rho + \Delta \mathbf{x}_t^2 (1-\rho)\\
        \boldsymbol{\theta}_t &\gets \boldsymbol{\theta}_{t-1} - \gamma \Delta \mathbf{x}_t
    \end{split}
\end{align}

Where the operations between vectors like the square is elementwise, i.e. $\mathbf{g}^2 = \mathbf{g} \odot \mathbf{g}$.\\
Another first-order gradient-base optimization algorithm for stochastic objective functions that is computationally efficient and compares favorably to other adaptive learning-method algorithms is \textbf{Adaptive Moment Estimation} (\textbf{Adam}) \cite{kingma2017}. In addition to storing an exponentially decaying average of squared gradients $\mathbf{v}_t$ like Adadelta, this algorithm also keeps an exponentially decaying average of past gradients $\mathbf{m}_t$, similar to momentum.
Let $\beta_1, \beta_2 \in [0,1)$ be the exponential decay rates for the moment estimates:

\begin{align}
    \label{eqn:Adam}
    \begin{split}
    \mathbf{g}_t &\gets \nabla_{\boldsymbol{\theta}} J(\boldsymbol{\theta}_{t-1}) \\
    \mathbf{m}_t &\gets \beta_1 \mathbf{m}_{t-1} + (1-\beta_1)\mathbf{g}_t \quad \text{ (Biased first moment estimate)}\\
    \mathbf{v}_t &\gets \beta_2 \mathbf{v}_{t-1} + (1-\beta_2) \mathbf{g}_t^2 \quad \text{ (Biased second raw moment estimate)}\\
    \mathbf{\hat{m}}_t &\gets \mathbf{m}_t / (1-\beta_1^t) \quad \text{ (Bias-corrected first moment estimate)}\\
    \mathbf{\hat{v}}_t &\gets \mathbf{v}_t / (1-\beta_2^t) \quad \text{ (Bias-corrected second raw moment estimate)}\\
    \boldsymbol{\theta}_t &\gets \boldsymbol{\theta}_{t-1} - \alpha \mathbf{\hat{m}}_t / \bigl( \sqrt{\mathbf{\hat{v}}_t} + \epsilon \bigr)
    \end{split}
\end{align}

According to \cite{kingma2017}, good default settings (in their machine learning experiments) are $\alpha=0.001$, $\beta_1=0.9$ and $\beta_2 = 0.999$.

In order to use this gradient-based algorithms we need to compute $\nabla_{\boldsymbol{\theta}} J(\boldsymbol{\theta})$, which is done using the \textbf{Backpropagation} algorithm \cite{rumelhart1986}, which leverages the composite structure of the neural network to efficiently compute the gradient \cite{damadi2023}.

\section{Convolutional Neural Networks}

When the input data is an image, a better approach for learning about $p(y | \mathbf{x})$ is to use Convolutional Neural Networks (CNN), since MLP tend to struggle with the computational complexity required to compute image data and the width required to train this kind of data may lead to overfitting \cite{oshea2015}. CNNs are comprised of three types of layers: convolutional layers, pooling layers and fully-connected layers (which are essentially a MLP).\\
The convolutional layer use learnable kernels:
